title: 我的百万知乎用户数据分析
categories: Python##分类
tags: [Python,爬虫]##标签，多标签格式为 [tag1,tag2,...]
keywords: Python,爬虫##文章关键词，多关键词格式为 keyword1,keywords2,...
description: 之前写的一个知乎爬虫抓到了上百万知乎用户的数据，但是一直没有时间写数据分析，今天来做一个有趣的数据分析吧，数据分析地址：[百万知乎用户数据分析](http://zhihu.jwlchina.cn)
date: 2016/12/01 21:19:25 
---


**这里是实时更新的知乎数据用户分析地址：[百万知乎用户数据分析](http://zhihu.jwlchina.cn)**

用户数据分析源码在这里：[ZhihuAnalyse](https://github.com/kong36088/ZhihuAnalyse)

爬虫项目源码放在我的github上：[ZhihuSpider](https://github.com/kong36088/ZhihuSpider)
爬虫代码分析可以看我的上一篇文章

**喜欢的话帮忙点个star呗:-D**

说个题外话：
今天下午的时候爬虫还在继续跑，知乎用户个人首页还用的是旧版
到了晚上7点发现爬虫居然爬不动了，十分疑惑，知乎个人中心竟然改版了，个人首页的url也改了，原来的爬虫用不了，
（不知道是不是知乎为了防止我爬数据做的措施，哈哈哈）
十分悲催，新版爬虫只能之后抽空出来再改一下了

# 效果图


![知乎爬虫1](/uploads/知乎用户数据分析1.png)
![知乎爬虫2](/uploads/知乎用户数据分析2.png)
![知乎爬虫3](/uploads/知乎用户数据分析3.png)
![知乎爬虫4](/uploads/知乎用户数据分析4.png)
![知乎爬虫5](/uploads/知乎用户数据分析5.png)
![知乎爬虫5](/uploads/知乎用户数据分析6.png)
![知乎爬虫5](/uploads/知乎用户数据分析7.png)



# 简介

主要利用SQL进行统计，并且利用redis进行数据缓存，ttl是6个小时，提高加载速度
